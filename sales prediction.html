import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.preprocessing import LabelEncoder
import joblib
import matplotlib.pyplot as plt

# Step 1: Load the dataset
file_path = "shopping_trends_dataset.csv"  # Replace with your dataset path
df = pd.read_csv(file_path)

# Step 2: Preprocess the data

# Check for missing values and inspect the first few rows
print(df.isna().sum())  # Check for missing values
print(df.head())  # Inspect the first few rows

# Ensure the 'Purchase_Date' column exists and is in the correct format
if 'Purchase_Date' in df.columns:
    df['Purchase_Date'] = pd.to_datetime(df['Purchase_Date'], errors='coerce')  # Convert to datetime format

    # Check if conversion is successful
    print(df['Purchase_Date'].head())
else:
    print("Column 'Purchase_Date' not found in the dataset.")

# Extract year and month from 'Purchase_Date'
df['Year'] = df['Purchase_Date'].dt.year
df['Month'] = df['Purchase_Date'].dt.month

# Handle missing 'Purchase_Date' values (if any)
df = df.dropna(subset=['Purchase_Date'])  # Drop rows with missing dates

# Fit LabelEncoder on 'Customer_Location'
label_encoder_location = LabelEncoder()
df['Customer_Location'] = label_encoder_location.fit_transform(df['Customer_Location'])

# Fit LabelEncoder on 'Product_Category'
label_encoder_category = LabelEncoder()
df['Product_Category'] = label_encoder_category.fit_transform(df['Product_Category'])

# Step 3: Define features (X) and target variable (y)
X = df[['Year', 'Month', 'Customer_Location', 'Product_Category']]  # Features for prediction
y = df['Total_Sales']  # Target variable (total sales)

# Step 4: Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: Initialize and train the Random Forest model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 6: Make predictions on the test set
y_pred = model.predict(X_test)

# Step 7: Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")

# Step 8: Visualize Actual vs Predicted Sales
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')  # Perfect prediction line
plt.title("Actual vs Predicted Sales")
plt.xlabel("Actual Sales")
plt.ylabel("Predicted Sales")
plt.grid(True)
plt.show()

# Step 9: Save the trained model (optional)
joblib.dump(model, 'sales_prediction_model.pkl')
print("Sales prediction model saved as 'sales_prediction_model.pkl'.")

# Step 10: Predict future sales (example)
# Fit LabelEncoder on 'Customer_Location' and 'Product_Category' to ensure they are encoded correctly
# We already fit these in Step 2, so we will now predict using them

# Handle unseen labels in future data (check if label exists in the training data)
def safe_transform(encoder, value):
    try:
        return encoder.transform([value])[0]
    except ValueError:
        # If label is unseen, return the most frequent label in the training data
        return encoder.transform([encoder.classes_[0]])[0]

# Predict future sales for a new product in a specific location
future_data = pd.DataFrame({
    'Year': [2025],
    'Month': [1],
    'Customer_Location': safe_transform(label_encoder_location, 'Urban'),  # Safe transform
    'Product_Category': safe_transform(label_encoder_category, 'Electronics')  # Safe transform
})

# Step 11: Predict future sales using the trained Random Forest model
future_sales = model.predict(future_data)
print(f"Predicted Sales for Future Data: {future_sales}")
